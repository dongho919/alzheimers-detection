{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5d96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "import gc\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1dcc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VGG19 Transfer', 'Convolutional Neural Network', 'ResNet50 Transfer']\n"
     ]
    }
   ],
   "source": [
    "# the index of the model to test. -1 indicates all models\n",
    "model_to_test = -1 \n",
    "# whether to start training from where we left off last time\n",
    "load_prev_models = True\n",
    "# number of epochs to train\n",
    "epochs = 30\n",
    "\n",
    "# binary classification\n",
    "class_names = ['NonDemented', 'Demented']\n",
    "# 2 classes\n",
    "num_classes = len(class_names)\n",
    "batch_size = 64\n",
    "# use the original image size (176x208), with RGB color channels (3)\n",
    "input_shape = (176, 208, 3) \n",
    "models = []\n",
    "_model_names = [\"VGG19 Transfer\", \"Convolutional Neural Network\", \"ResNet50 Transfer\"]\n",
    "\n",
    "# pick the models to train based on the `model_to_test` switch value\n",
    "model_names = []\n",
    "\n",
    "# -1 means all models\n",
    "if model_to_test == -1:\n",
    "    model_names = _model_names\n",
    "# otherwise, only one specified model gets tested\n",
    "else:\n",
    "    model_names.append(_model_names[model_to_test])\n",
    "print(model_names)\n",
    "\n",
    "# directory to save the models under (folder doesn't need to be present; the code will create one if it doesn't exist)\n",
    "models_dir = './saved models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113667f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 images belonging to 2 classes.\n",
      "Found 1279 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# the paths to load the data from\n",
    "train_dir = pathlib.Path('../Project/Alzheimer_s Dataset_binary/train')\n",
    "test_dir = pathlib.Path('../Project/Alzheimer_s Dataset_binary/test')\n",
    "\n",
    "# horizontal flip and normalization are on (for better training)\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True,\n",
    "                                                       #rotation_range=10,\n",
    "                                                       rescale=1./255\n",
    "                                                       #brightness_range=(0.8,1.1),\n",
    "                                                       #zoom_range=0.2,\n",
    "                                                       #width_shift_range=0.1,\n",
    "                                                       #height_shift_range=0.1\n",
    "                                                      )\n",
    "\n",
    "# only normalization is on (you don't need to flip test images)\n",
    "simple_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# load the training images with horizontal flipping\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        classes=class_names,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        target_size=input_shape[0:2])\n",
    "\n",
    "# load the test images just as they are\n",
    "test_generator = simple_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        classes=class_names,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        target_size=input_shape[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a372cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## VGG19 ########################\n",
    "if model_to_test == -1 or model_to_test == 0:\n",
    "    vgg = keras.applications.VGG19(\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling=max)\n",
    "    \n",
    "    # freeze the whole VGG19 model\n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #### Create a transfer learning model ####\n",
    "\n",
    "    transfer_vgg19 = keras.models.Sequential([\n",
    "            keras.Input(input_shape),\n",
    "            #layers.GaussianNoise(0.1),\n",
    "            vgg,\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.6),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(num_classes, activation='softmax'),\n",
    "\n",
    "        ])\n",
    "\n",
    "    models.append(transfer_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115535c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a CNN from scratch ####\n",
    "\n",
    "if model_to_test == -1 or model_to_test == 1:\n",
    "    # Gaussian noise -> 5 convolution blocks -> flatten -> 3 dense layers\n",
    "    cnn = keras.models.Sequential([\n",
    "            keras.Input(input_shape),\n",
    "            layers.GaussianNoise(0.15),\n",
    "            layers.Conv2D(16, kernel_size=(3,3), activation='relu'),\n",
    "            layers.Conv2D(16, kernel_size=(3,3), activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            layers.SeparableConv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "            layers.SeparableConv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            layers.SeparableConv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "            layers.SeparableConv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            layers.SeparableConv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "            layers.SeparableConv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            layers.SeparableConv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "            layers.SeparableConv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(num_classes, activation='softmax'),\n",
    "        ])\n",
    "\n",
    "    models.append(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994153af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_to_test == -1 or model_to_test == 2:\n",
    "    input_t = keras.Input(shape=input_shape)\n",
    "    ResNet = keras.applications.ResNet50(\n",
    "            include_top=False,\n",
    "            input_tensor=input_t,\n",
    "            pooling=max)\n",
    "\n",
    "    # freeze the whole ResNet50 model\n",
    "    for layer in ResNet.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    transfer_resnet = keras.models.Sequential([\n",
    "        ResNet,\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Flatten(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(2,activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    models.append(transfer_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e885c59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model #1: VGG19 Transfer\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 5, 6, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 15360)             61440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               7864832   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 28,035,650\n",
      "Trainable params: 7,979,266\n",
      "Non-trainable params: 20,056,384\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "model #2: Convolutional Neural Network\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois (None, 176, 208, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 174, 206, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 172, 204, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 172, 204, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 86, 102, 16)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 84, 100, 32)       688       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 82, 98, 32)        1344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 82, 98, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 41, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 39, 47, 64)        2400      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 37, 45, 64)        4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 45, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 16, 20, 128)       8896      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 14, 18, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 5, 7, 256)         34176     \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 3, 5, 256)         68096     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 151,394\n",
      "Trainable params: 150,338\n",
      "Non-trainable params: 1,056\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "model #3: ResNet50 Transfer\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 6, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6, 7, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6, 7, 128)         262272    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6, 7, 64)          8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6, 7, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1344)              5376      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 2690      \n",
      "=================================================================\n",
      "Total params: 23,876,578\n",
      "Trainable params: 282,082\n",
      "Non-trainable params: 23,594,496\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "weights for model #1 (VGG19 Transfer) loaded: acc=79.43705916404724%\n",
      "weights for model #2 (Convolutional Neural Network) loaded: acc=70.52384614944458%\n",
      "weights for model #3 (ResNet50 Transfer) loaded: acc=70.05472779273987%\n"
     ]
    }
   ],
   "source": [
    "# print the summary/summaries of the model(s)\n",
    "for i in range(len(models)):\n",
    "    print(f\"model #{i+1}: {model_names[i]}\")\n",
    "    models[i].summary()\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# create a folder to save models if it doesn't exist already\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "# load model weights and test them only if the weight files exist and load_prev_models is set to True\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    if load_prev_models and os.path.exists(models_dir + model_names[i] + \".index\"):\n",
    "        model.load_weights(models_dir + model_names[i])\n",
    "    \n",
    "    # model should be compiled whether it's blank or loaded, because this is required before you can actually fit the model\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    # test accuracy if model has been loaded\n",
    "    if load_prev_models and os.path.exists(models_dir + model_names[i] + \".index\"):\n",
    "        loss, acc = model.evaluate(test_generator, verbose=0)\n",
    "        print(f\"weights for model #{i+1} ({model_names[i]}) loaded: acc={acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "205343a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "81/81 [==============================] - 148s 2s/step - loss: 0.6116 - accuracy: 0.6796 - val_loss: 0.6933 - val_accuracy: 0.4996\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 140s 2s/step - loss: 0.5410 - accuracy: 0.7211 - val_loss: 0.6953 - val_accuracy: 0.4996\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 139s 2s/step - loss: 0.4816 - accuracy: 0.7583 - val_loss: 0.7060 - val_accuracy: 0.4996\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - 140s 2s/step - loss: 0.4273 - accuracy: 0.7965 - val_loss: 0.7319 - val_accuracy: 0.4996\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - 139s 2s/step - loss: 0.3678 - accuracy: 0.8358 - val_loss: 0.9906 - val_accuracy: 0.4996\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - 139s 2s/step - loss: 0.3086 - accuracy: 0.8635 - val_loss: 1.4528 - val_accuracy: 0.4996\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - 145s 2s/step - loss: 0.2642 - accuracy: 0.8926 - val_loss: 1.5873 - val_accuracy: 0.4996\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - 141s 2s/step - loss: 0.2225 - accuracy: 0.9106 - val_loss: 1.2627 - val_accuracy: 0.4996\n",
      "Epoch 9/30\n",
      " 2/81 [..............................] - ETA: 2:28 - loss: 0.1009 - accuracy: 0.9766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19528/67002137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"::::::: model #{len(histories)} training complete :::::::\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# print the lengthy messages when you're testing one model only. If you're training all of them, better make it silent\n",
    "if len(models) == 1:\n",
    "    verbosity = 1\n",
    "else:\n",
    "    verbosity = 0\n",
    "    \n",
    "# fit and save each model, while saving each model's training history\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    histories.append( model.fit(train_generator, epochs=epochs, validation_data=test_generator, verbose=verbosity) )\n",
    "    print(f\"::::::: model #{len(histories)} training complete :::::::\")\n",
    "    model.save_weights(models_dir + model_names[i])\n",
    "    print(f\":::::::   model #{len(histories)} weights saved   :::::::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c455d000",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'histories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3136/780594729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"training acc.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'histories' is not defined"
     ]
    }
   ],
   "source": [
    "# this one is for a multi-model training result (building subplots); plot accuracy against epoch\n",
    "if len(histories) > 1:\n",
    "    fig, axs = plt.subplots( len(histories), figsize=(6,5*len(histories)) )\n",
    "    for i in range(len(histories)):\n",
    "        history = histories[i]\n",
    "        axs[i].plot(history.history['accuracy'], label = \"training acc.\")\n",
    "        axs[i].plot(history.history['val_accuracy'], label = \"validation acc.\")\n",
    "        axs[i].legend(['training acc.', 'validation acc.'], loc='upper left')\n",
    "        axs[i].set_title(model_names[i])\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='epochs', ylabel='accuracy')\n",
    "\n",
    "# this one is for a single-model training result (just one whole plot, virtually the same as the one above)\n",
    "else:\n",
    "    history = histories[0]\n",
    "    plt.plot(history.history['accuracy'], label = \"training acc.\")\n",
    "    plt.plot(history.history['val_accuracy'], label = \"validation acc.\")\n",
    "    plt.legend(['training acc.', 'validation acc.'], loc='upper left')\n",
    "    plt.title(model_names[i])\n",
    "\n",
    "# change the file name to save the plot into a different png\n",
    "plt.savefig(\"../Project/Result2/ensemble_model_300_2.png\")\n",
    "\n",
    "# prints the final accuracy/accuracies of the model(s)\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=['accuracy'])\n",
    "    loss, acc = model.evaluate(test_generator, verbose=0)\n",
    "    print(f\"weights for model #{i+1} ({model_names[i]}) loaded: acc={acc*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4583d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 176, 208, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 2)            28035650    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2)            151394      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 2)            23876578    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 2)            0           sequential[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "                                                                 sequential_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 52,063,622\n",
      "Trainable params: 8,411,686\n",
      "Non-trainable params: 43,651,936\n",
      "__________________________________________________________________________________________________\n",
      "20/20 [==============================] - 10s 423ms/step - loss: 0.5939 - accuracy: 0.7952\n"
     ]
    }
   ],
   "source": [
    "# define the ensemble input shape (basically just the image shape (176, 208, 3))\n",
    "model_input = keras.Input(shape=input_shape)\n",
    "# a pseudo-ensemble model using keras' Average layer; this is not a true voting system\n",
    "ensemble_output = layers.Average()([model(model_input) for model in models])\n",
    "# construct the model\n",
    "ensemble_model = keras.Model(inputs=model_input, outputs=ensemble_output)\n",
    "ensemble_model.summary()\n",
    "\n",
    "# since the constituent models are already trained, all we need to do is evaluate it\n",
    "ensemble_model.compile(loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"])\n",
    "loss, acc = ensemble_model.evaluate(test_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
